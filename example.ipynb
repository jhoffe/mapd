{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import mapd\n",
    "import torchvision\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset MNIST\n    Number of datapoints: 60000\n    Root location: data\n    Split: Train"
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_ROOT = \"data\"\n",
    "torchvision.datasets.MNIST(root=MNIST_ROOT, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class IDXDataset(Dataset):\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index], index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "from lightning.pytorch.trainer.states import TrainerFn\n",
    "from copy import deepcopy\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "import torch\n",
    "from lightning import LightningModule\n",
    "from typing import Any, Optional, List, Dict\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MAPDModule(LightningModule, metaclass=ABCMeta):\n",
    "    mapd_current_indices_: torch.Tensor = torch.empty(0, dtype=torch.int64)\n",
    "    mapd_indices_: List[Tensor] = []\n",
    "\n",
    "    mapd_losses_: List[Tensor] = []\n",
    "    mapd_stages_: List[str] = []\n",
    "    mapd_proxy_metrics_: List[Tensor] = []\n",
    "\n",
    "    as_proxies_: bool = False\n",
    "    as_probes_: bool = False\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.mapd_current_indices_ = torch.empty(0, dtype=torch.int64)\n",
    "        self.mapd_losses_ = []\n",
    "        self.mapd_stages_ = []\n",
    "        self.mapd_proxy_metrics_ = []\n",
    "        self.mapd_indices_ = []\n",
    "        self.as_proxies_ = False\n",
    "        self.as_probes_ = False\n",
    "        self.is_val_probes_ = False\n",
    "\n",
    "        self.probes_dataset = None\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def batch_loss(self, logits: Any, y: Any) -> Tensor:\n",
    "        raise NotImplemented(\"batch_loss method not implemented\")\n",
    "\n",
    "    def on_before_batch_transfer(self, batch: Any, dataloader_idx: int) -> Any:\n",
    "        batch, indices = batch\n",
    "        self.mapd_current_indices_ = indices\n",
    "        return batch\n",
    "\n",
    "    def batch_proxy_metric(self, logits: Any, y: Any) -> Tensor:\n",
    "        softmax = torch.softmax(logits, dim=1)\n",
    "\n",
    "        # softmax confidence on correct class\n",
    "        return softmax[torch.arange(softmax.shape[0]), y]\n",
    "\n",
    "    def _mapd_log_proxy(self, logits: Any, y: Any):\n",
    "        proxy_metrics = self.batch_proxy_metric(logits, y).detach()\n",
    "        self.mapd_proxy_metrics_.append(proxy_metrics)\n",
    "\n",
    "    def _mapd_log_probes(self, logits: Any, y: Any):\n",
    "        batch_losses = self.batch_loss(logits, y).detach()\n",
    "        self.mapd_losses_.append(batch_losses)\n",
    "        self.mapd_stages_ += [\"train\" if self.training else \"val\"] * batch_losses.shape[0]\n",
    "\n",
    "    def mapd_log(self, logits: Any, y: Any) -> \"MAPDModule\":\n",
    "        if not self.trainer.sanity_checking:\n",
    "            self.mapd_indices_.append(self.mapd_current_indices_)\n",
    "\n",
    "            if self.as_proxies_:\n",
    "                self._mapd_log_proxy(logits, y)\n",
    "                return self\n",
    "\n",
    "            if (self.training or (not self.training and self.is_val_probes_)):\n",
    "                self._mapd_log_probes(logits, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _reset_mapd_attrs(self) -> \"MAPDModule\":\n",
    "        self.mapd_current_indices_ = torch.empty(0, dtype=torch.int64)\n",
    "        self.mapd_losses_ = []\n",
    "        self.mapd_proxy_metrics_ = []\n",
    "        self.mapd_indices_ = []\n",
    "        self.mapd_stages_ = []\n",
    "\n",
    "        return self\n",
    "\n",
    "    def as_proxies(self) -> \"MAPDModule\":\n",
    "        self.as_proxies_ = True\n",
    "        self.as_probes_ = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def as_probes(self, probes_dataset: Dataset) -> \"MAPDModule\":\n",
    "        self.as_probes_ = True\n",
    "        self.as_proxies_ = False\n",
    "\n",
    "        self.probes_dataset = deepcopy(probes_dataset)\n",
    "        self.probes_dataset.only_probes = True\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _write_proxies(self):\n",
    "        sample_indices = torch.cat(self.mapd_indices_).cpu().numpy()\n",
    "        sample_proxy_metrics = torch.cat(self.mapd_proxy_metrics_).cpu().numpy()\n",
    "        epochs = np.full(sample_indices.shape, self.current_epoch)\n",
    "\n",
    "        table = pa.table(\n",
    "            [\n",
    "                pa.array(sample_indices),\n",
    "                pa.array(sample_proxy_metrics),\n",
    "                pa.array(epochs),\n",
    "            ],\n",
    "            names=[\"sample_index\", \"proxy_metric\", \"epoch\"],\n",
    "        )\n",
    "\n",
    "        ds.write_dataset(table, \"proxies\",\n",
    "                         partitioning=ds.partitioning(pa.schema([(\"epoch\", pa.int64())]), flavor=\"filename\"),\n",
    "                         existing_data_behavior=\"overwrite_or_ignore\", format=\"parquet\")\n",
    "\n",
    "    def _write_probes(self):\n",
    "        sample_indices = torch.cat(self.mapd_indices_).cpu().numpy()\n",
    "        sample_losses = torch.cat(self.mapd_losses_).cpu().numpy()\n",
    "        epochs = np.full(sample_indices.shape, self.current_epoch)\n",
    "\n",
    "        table = pa.table(\n",
    "            [\n",
    "                pa.array(sample_indices),\n",
    "                pa.array(sample_losses),\n",
    "                pa.array(epochs),\n",
    "                pa.array(self.mapd_stages_)\n",
    "            ],\n",
    "            names=[\"sample_index\", \"loss\", \"epoch\", \"stage\"],\n",
    "        )\n",
    "\n",
    "        ds.write_dataset(table, \"probes\",\n",
    "                         partitioning=ds.partitioning(pa.schema([(\"epoch\", pa.int64()), (\"stage\", pa.string())]), flavor=\"filename\"),\n",
    "                         existing_data_behavior=\"overwrite_or_ignore\", format=\"parquet\")\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        if self.as_proxies_:\n",
    "            self._write_proxies()\n",
    "\n",
    "        if self.as_probes_:\n",
    "            self._write_probes()\n",
    "\n",
    "        self._reset_mapd_attrs()\n",
    "\n",
    "\n",
    "    def on_validation_batch_start(self, batch: Any, batch_idx: int, dataloader_idx: int) -> None:\n",
    "        if self.as_proxies_:\n",
    "            return\n",
    "\n",
    "        self.is_val_probes_ = dataloader_idx == 0\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResNet18(MAPDModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_epochs: int = 10,\n",
    "            lr: float = 0.05,\n",
    "            momentum: float = 0.9,\n",
    "            weight_decay: float = 0.0005\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "        self.max_epochs = max_epochs\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "    def mapd_settings(self):\n",
    "        return {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def batch_loss(self, logits, y) -> torch.Tensor:\n",
    "        return F.cross_entropy(logits, y, reduction=\"none\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.mapd_log(logits, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx: int = 0):\n",
    "        x, y = batch\n",
    "\n",
    "        logits = self.forward(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        if dataloader_idx == 0:\n",
    "            self.mapd_log(logits, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.lr\n",
    "        )\n",
    "\n",
    "        return {\"optimizer\": optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"data\", batch_size: int = 32, num_workers=16):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "        self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "        mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "        self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        self.mnist_train = IDXDataset(self.mnist_train)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers, prefetch_factor=8)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers, prefetch_factor=8)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=self.batch_size, num_workers=self.num_workers, prefetch_factor=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jonashoffmann/.applications/miniconda3/envs/mapd-pkg/lib/python3.9/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | Net  | 21.8 K\n",
      "-------------------------------\n",
      "21.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.8 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c435368079764efbb2fbfa9caa85798e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "module = ResNet18()\n",
    "dm = MNISTDataModule(batch_size=512, num_workers=16)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "mnist_test = MNIST(MNIST_ROOT, train=False, transform=transform)\n",
    "mnist_predict = MNIST(MNIST_ROOT, train=False, transform=transform)\n",
    "mnist_full = MNIST(MNIST_ROOT, train=True, transform=transform)\n",
    "mnist_train, mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "mnist_train = IDXDataset(mnist_train)\n",
    "\n",
    "dl = DataLoader(mnist_train, batch_size=512, shuffle=True, num_workers=16, prefetch_factor=8)\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "trainer_proxy = L.Trainer(accelerator=\"gpu\", max_epochs=100)\n",
    "trainer_probes = L.Trainer(accelerator=\"gpu\", max_epochs=100)\n",
    "\n",
    "# Proxy\n",
    "trainer_proxy.fit(module.as_proxies(), train_dataloaders=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class ProxyCalculator:\n",
    "    def __init__(self, proxy_dataset_path: os.PathLike, proxy_name: str):\n",
    "        self.proxy_df = None\n",
    "        self.proxy_dataset_path = proxy_dataset_path\n",
    "        self.proxy_dataset = ds.dataset(proxy_dataset_path, format=\"parquet\", partitioning=ds.partitioning(pa.schema([(\"epoch\", pa.int64())]), flavor=\"filename\"))\n",
    "        self.proxy_name = proxy_name\n",
    "\n",
    "    def load(self, columns: list = None):\n",
    "        self.proxy_df = self.proxy_dataset.to_table(columns=columns).to_pandas()\n",
    "        self.proxy_df[\"epoch\"] = self.proxy_df[\"epoch\"].astype(int)\n",
    "\n",
    "        return self.proxy_df\n",
    "\n",
    "    def calculate_proxy_scores(self) -> Dict[int, float]:\n",
    "        scores = self.proxy_df.groupby([\"sample_index\"]).agg({self.proxy_name: \"sum\"})\n",
    "\n",
    "        scores[self.proxy_name] = (scores[self.proxy_name] - scores[self.proxy_name].min()) / (\n",
    "            scores[self.proxy_name].max() - scores[self.proxy_name].min()\n",
    "        )\n",
    "\n",
    "        return scores[self.proxy_name].to_dict()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 0.9850846529006958,\n 1: 0.9776061177253723,\n 2: 0.973325788974762,\n 3: 0.8434043526649475,\n 4: 0.8119612336158752,\n 5: 0.9781427979469299,\n 6: 0.9605704545974731,\n 7: 0.9775375127792358,\n 8: 0.8739024996757507,\n 9: 0.9128909111022949,\n 10: 0.9740433096885681,\n 11: 0.9452816843986511,\n 12: 0.9805165529251099,\n 13: 0.8826597332954407,\n 14: 0.9644473791122437,\n 15: 0.9678345322608948,\n 16: 0.961044430732727,\n 17: 0.9716731309890747,\n 18: 0.6625897288322449,\n 19: 0.9695131778717041,\n 20: 0.9626560211181641,\n 21: 0.9147055149078369,\n 22: 0.9414896368980408,\n 23: 0.9732064604759216,\n 24: 0.9828078150749207,\n 25: 0.9794906973838806,\n 26: 0.8485358357429504,\n 27: 0.9805017709732056,\n 28: 0.9790338277816772,\n 29: 0.9798418879508972,\n 30: 0.4323117733001709,\n 31: 0.9609223008155823,\n 32: 0.9870248436927795,\n 33: 0.7986031770706177,\n 34: 0.884515106678009,\n 35: 0.9709193706512451,\n 36: 0.8677396774291992,\n 37: 0.956750214099884,\n 38: 0.9426982998847961,\n 39: 0.9036018252372742,\n 40: 0.8129493594169617,\n 41: 0.8331753015518188,\n 42: 0.9511559009552002,\n 43: 0.9529299736022949,\n 44: 0.9351353049278259,\n 45: 0.9795640110969543,\n 46: 0.9668378233909607,\n 47: 0.984825849533081,\n 48: 0.9715114831924438,\n 49: 0.5662817358970642,\n 50: 0.8742685914039612,\n 51: 0.9455901980400085,\n 52: 0.7891188263893127,\n 53: 0.9727184772491455,\n 54: 0.9566991925239563,\n 55: 0.8484353423118591,\n 56: 0.947340726852417,\n 57: 0.943168044090271,\n 58: 0.5601527690887451,\n 59: 0.9685956835746765,\n 60: 0.9867852330207825,\n 61: 0.9814180731773376,\n 62: 0.9701763391494751,\n 63: 0.9814291596412659,\n 64: 0.8760325908660889,\n 65: 0.9254973530769348,\n 66: 0.9536434412002563,\n 67: 0.9454708695411682,\n 68: 0.9908546805381775,\n 69: 0.9516555666923523,\n 70: 0.779763400554657,\n 71: 0.6932449340820312,\n 72: 0.9618828892707825,\n 73: 0.9645713567733765,\n 74: 0.9272761344909668,\n 75: 0.9688910841941833,\n 76: 0.9763907790184021,\n 77: 0.9608444571495056,\n 78: 0.7843935489654541,\n 79: 0.9622092247009277,\n 80: 0.9802683591842651,\n 81: 0.9802832007408142,\n 82: 0.9700415730476379,\n 83: 0.9731234312057495,\n 84: 0.9476187229156494,\n 85: 0.8853107690811157,\n 86: 0.9718919396400452,\n 87: 0.9699927568435669,\n 88: 0.9663802981376648,\n 89: 0.9178815484046936,\n 90: 0.9877639412879944,\n 91: 0.8892084956169128,\n 92: 0.9653534293174744,\n 93: 0.9625749588012695,\n 94: 0.9515742659568787,\n 95: 0.9383412003517151,\n 96: 0.9664451479911804,\n 97: 0.9698247909545898,\n 98: 0.9693132042884827,\n 99: 0.98011714220047,\n 100: 0.8583759069442749,\n 101: 0.9797555208206177,\n 102: 0.8814601898193359,\n 103: 0.8790051341056824,\n 104: 0.9733055830001831,\n 105: 0.9357929825782776,\n 106: 0.9845057725906372,\n 107: 0.9399572014808655,\n 108: 0.9875786304473877,\n 109: 0.9928456544876099,\n 110: 0.9775310754776001,\n 111: 0.8138596415519714,\n 112: 0.9782917499542236,\n 113: 0.9898948073387146,\n 114: 0.9603678584098816,\n 115: 0.970481812953949,\n 116: 0.912301242351532,\n 117: 0.9129794836044312,\n 118: 0.6617487072944641,\n 119: 0.9631192088127136,\n 120: 0.950212299823761,\n 121: 0.9614590406417847,\n 122: 0.9825674295425415,\n 123: 0.9310911893844604,\n 124: 0.9582844972610474,\n 125: 0.922000527381897,\n 126: 0.9376249313354492,\n 127: 0.9812067747116089,\n 128: 0.8984025120735168,\n 129: 0.801095187664032,\n 130: 0.9366708993911743,\n 131: 0.9700004458427429,\n 132: 0.9758493304252625,\n 133: 0.9581348299980164,\n 134: 0.9705490469932556,\n 135: 0.9544239640235901,\n 136: 0.9156296849250793,\n 137: 0.8313215970993042,\n 138: 0.9617264270782471,\n 139: 0.9606781005859375,\n 140: 0.9591036438941956,\n 141: 0.9826539158821106,\n 142: 0.959434986114502,\n 143: 0.9253854155540466,\n 144: 0.977188229560852,\n 145: 0.9130880832672119,\n 146: 0.8543046712875366,\n 147: 0.8981016278266907,\n 148: 0.9826064109802246,\n 149: 0.7041469216346741,\n 150: 0.9607356786727905,\n 151: 0.9883073568344116,\n 152: 0.9853947162628174,\n 153: 0.9551448225975037,\n 154: 0.34337660670280457,\n 155: 0.9581001400947571,\n 156: 0.9373680353164673,\n 157: 0.9226897954940796,\n 158: 0.8387447595596313,\n 159: 0.9734723567962646,\n 160: 0.9393828511238098,\n 161: 0.9584764838218689,\n 162: 0.9550816416740417,\n 163: 0.8748587369918823,\n 164: 0.9885990619659424,\n 165: 0.8403603434562683,\n 166: 0.8992761373519897,\n 167: 0.9773367643356323,\n 168: 0.8686636686325073,\n 169: 0.9685654044151306,\n 170: 0.9602121114730835,\n 171: 0.989245593547821,\n 172: 0.9677523374557495,\n 173: 0.9439570903778076,\n 174: 0.95380038022995,\n 175: 0.9101465940475464,\n 176: 0.9598833918571472,\n 177: 0.9663121700286865,\n 178: 0.9888415336608887,\n 179: 0.979418933391571,\n 180: 0.9539174437522888,\n 181: 0.964597761631012,\n 182: 0.9589074850082397,\n 183: 0.9471535682678223,\n 184: 0.803222119808197,\n 185: 0.887157142162323,\n 186: 0.9748916625976562,\n 187: 0.9564504623413086,\n 188: 0.5833674669265747,\n 189: 0.8947182297706604,\n 190: 0.9583075642585754,\n 191: 0.9860000610351562,\n 192: 0.9697571992874146,\n 193: 0.9346508383750916,\n 194: 0.9770961999893188,\n 195: 0.925632894039154,\n 196: 0.8859497904777527,\n 197: 0.14456354081630707,\n 198: 0.9836331009864807,\n 199: 0.8875049352645874,\n 200: 0.9564374089241028,\n 201: 0.9365142583847046,\n 202: 0.9515309929847717,\n 203: 0.9669805765151978,\n 204: 0.9789702892303467,\n 205: 0.6290010809898376,\n 206: 0.9751490950584412,\n 207: 0.9972227811813354,\n 208: 0.9450597763061523,\n 209: 0.9631356000900269,\n 210: 0.9634703993797302,\n 211: 0.9096675515174866,\n 212: 0.979765772819519,\n 213: 0.9739590287208557,\n 214: 0.9775364995002747,\n 215: 0.9748573899269104,\n 216: 0.9458872079849243,\n 217: 0.9650295972824097,\n 218: 0.9566791653633118,\n 219: 0.9868929982185364,\n 220: 0.9252661466598511,\n 221: 0.8919997811317444,\n 222: 0.974982500076294,\n 223: 0.9725531339645386,\n 224: 0.7865442037582397,\n 225: 0.9669579863548279,\n 226: 0.9545661807060242,\n 227: 0.9780898690223694,\n 228: 0.9753159880638123,\n 229: 0.9773267507553101,\n 230: 0.9809206128120422,\n 231: 0.9683259725570679,\n 232: 0.9556013941764832,\n 233: 0.9739381074905396,\n 234: 0.9103696942329407,\n 235: 0.9303104877471924,\n 236: 0.810425341129303,\n 237: 0.9530744552612305,\n 238: 0.9863015413284302,\n 239: 0.9072328209877014,\n 240: 0.9578555226325989,\n 241: 0.9579758048057556,\n 242: 0.9602769017219543,\n 243: 0.9380635023117065,\n 244: 0.9875079989433289,\n 245: 0.9646788239479065,\n 246: 0.915175199508667,\n 247: 0.9545621275901794,\n 248: 0.9814602136611938,\n 249: 0.9648362994194031,\n 250: 0.9674196839332581,\n 251: 0.9363098740577698,\n 252: 0.988044261932373,\n 253: 0.9808765649795532,\n 254: 0.9573419690132141,\n 255: 0.951126754283905,\n 256: 0.8251544237136841,\n 257: 0.9800136685371399,\n 258: 0.953336238861084,\n 259: 0.9663695096969604,\n 260: 0.9708165526390076,\n 261: 0.9790859818458557,\n 262: 0.9586742520332336,\n 263: 0.9420035481452942,\n 264: 0.9201312065124512,\n 265: 0.9709190726280212,\n 266: 0.8594543933868408,\n 267: 0.9465810656547546,\n 268: 0.9636560678482056,\n 269: 0.8287363052368164,\n 270: 0.9479536414146423,\n 271: 0.9722871780395508,\n 272: 0.9433872699737549,\n 273: 0.9548917412757874,\n 274: 0.9454464912414551,\n 275: 0.9400738477706909,\n 276: 0.9681768417358398,\n 277: 0.9879439473152161,\n 278: 0.9810325503349304,\n 279: 0.8434127569198608,\n 280: 0.9560296535491943,\n 281: 0.982074499130249,\n 282: 0.7883688807487488,\n 283: 0.8178768754005432,\n 284: 0.9944276213645935,\n 285: 0.8725168108940125,\n 286: 0.985788881778717,\n 287: 0.9814227223396301,\n 288: 0.9560417532920837,\n 289: 0.8562489748001099,\n 290: 0.8935100436210632,\n 291: 0.9617260098457336,\n 292: 0.9108050465583801,\n 293: 0.958590567111969,\n 294: 0.9854549169540405,\n 295: 0.915865957736969,\n 296: 0.9475109577178955,\n 297: 0.9781641364097595,\n 298: 0.8247984647750854,\n 299: 0.7247288227081299,\n 300: 0.5134828686714172,\n 301: 0.9739725589752197,\n 302: 0.9775772094726562,\n 303: 0.9760323762893677,\n 304: 0.8289363980293274,\n 305: 0.9808651804924011,\n 306: 0.9662405848503113,\n 307: 0.9414154291152954,\n 308: 0.912786602973938,\n 309: 0.9814825654029846,\n 310: 0.9869552850723267,\n 311: 0.9334577918052673,\n 312: 0.8705784678459167,\n 313: 0.9587039947509766,\n 314: 0.766407310962677,\n 315: 0.9621944427490234,\n 316: 0.993727445602417,\n 317: 0.9410243630409241,\n 318: 0.9774419665336609,\n 319: 0.9514326453208923,\n 320: 0.9708693623542786,\n 321: 0.8185995221138,\n 322: 0.965789794921875,\n 323: 0.8520897626876831,\n 324: 0.9368822574615479,\n 325: 0.9870718121528625,\n 326: 0.9655814170837402,\n 327: 0.8280677199363708,\n 328: 0.959753155708313,\n 329: 0.4993031919002533,\n 330: 0.9273175001144409,\n 331: 0.729896605014801,\n 332: 0.9685949683189392,\n 333: 0.9215518236160278,\n 334: 0.7921831607818604,\n 335: 0.9525821805000305,\n 336: 0.7353471517562866,\n 337: 0.9477342367172241,\n 338: 0.9878466129302979,\n 339: 0.9550668597221375,\n 340: 0.9816881418228149,\n 341: 0.9309992790222168,\n 342: 0.9732336401939392,\n 343: 0.8983066082000732,\n 344: 0.9445992112159729,\n 345: 0.9531354904174805,\n 346: 0.9644618630409241,\n 347: 0.9191242456436157,\n 348: 0.7765830159187317,\n 349: 0.9730716347694397,\n 350: 0.9658424854278564,\n 351: 0.9783229827880859,\n 352: 0.8894486427307129,\n 353: 0.9159072637557983,\n 354: 0.9416133165359497,\n 355: 0.990179181098938,\n 356: 0.9755042195320129,\n 357: 0.9389256238937378,\n 358: 0.9798226952552795,\n 359: 0.8783488869667053,\n 360: 0.9455318450927734,\n 361: 0.9247874617576599,\n 362: 0.9306418299674988,\n 363: 0.7107563018798828,\n 364: 0.8590872883796692,\n 365: 0.9797592163085938,\n 366: 0.9755941033363342,\n 367: 0.9919281005859375,\n 368: 0.7787736058235168,\n 369: 0.9698997139930725,\n 370: 0.9600492715835571,\n 371: 0.9798186421394348,\n 372: 0.9603654146194458,\n 373: 0.8837870359420776,\n 374: 0.6319735050201416,\n 375: 0.9719321131706238,\n 376: 0.9603635668754578,\n 377: 0.9492998719215393,\n 378: 0.9623986482620239,\n 379: 0.9801648855209351,\n 380: 0.9884642362594604,\n 381: 0.9796757698059082,\n 382: 0.9608476161956787,\n 383: 0.9733713269233704,\n 384: 0.9680434465408325,\n 385: 0.9868554472923279,\n 386: 0.9725106358528137,\n 387: 0.9629775881767273,\n 388: 0.8715487122535706,\n 389: 0.9084205031394958,\n 390: 0.9824566841125488,\n 391: 0.9800630211830139,\n 392: 0.9784331917762756,\n 393: 0.8584238290786743,\n 394: 0.9764264822006226,\n 395: 0.9421193599700928,\n 396: 0.9814288020133972,\n 397: 0.8377463817596436,\n 398: 0.991220235824585,\n 399: 0.9575469493865967,\n 400: 0.9637743830680847,\n 401: 0.9411010146141052,\n 402: 0.9619442820549011,\n 403: 0.9590622782707214,\n 404: 0.9830855131149292,\n 405: 0.9580889344215393,\n 406: 0.9527912735939026,\n 407: 0.8589117527008057,\n 408: 0.9577228426933289,\n 409: 0.9620763659477234,\n 410: 0.9439553618431091,\n 411: 0.9746905565261841,\n 412: 0.8640921115875244,\n 413: 0.7685314416885376,\n 414: 0.9476346373558044,\n 415: 0.8924155831336975,\n 416: 0.9489184021949768,\n 417: 0.9322282075881958,\n 418: 0.9765019416809082,\n 419: 0.9297440052032471,\n 420: 0.9646688103675842,\n 421: 0.9792479872703552,\n 422: 0.9754259586334229,\n 423: 0.9557244181632996,\n 424: 0.8629959225654602,\n 425: 0.9521297812461853,\n 426: 0.8041812181472778,\n 427: 0.9807487726211548,\n 428: 0.967354953289032,\n 429: 0.9326429963111877,\n 430: 0.9803439378738403,\n 431: 0.951736330986023,\n 432: 0.9766109585762024,\n 433: 0.9693719148635864,\n 434: 0.9707393646240234,\n 435: 0.8938862681388855,\n 436: 0.9698880314826965,\n 437: 0.9638999700546265,\n 438: 0.9624689817428589,\n 439: 0.932761549949646,\n 440: 0.9186232089996338,\n 441: 0.7753034234046936,\n 442: 0.9813386797904968,\n 443: 0.3128458559513092,\n 444: 0.9743182063102722,\n 445: 0.9287054538726807,\n 446: 0.840491533279419,\n 447: 0.4166741967201233,\n 448: 0.9583468437194824,\n 449: 0.8660300970077515,\n 450: 0.9082310199737549,\n 451: 0.9761564135551453,\n 452: 0.8954830169677734,\n 453: 0.9671348929405212,\n 454: 0.9877104759216309,\n 455: 0.9794031977653503,\n 456: 0.9695107340812683,\n 457: 0.9541922807693481,\n 458: 0.9453281164169312,\n 459: 0.9689484238624573,\n 460: 0.4626707434654236,\n 461: 0.9789186716079712,\n 462: 0.654597282409668,\n 463: 0.9411302208900452,\n 464: 0.9873921275138855,\n 465: 0.8783702254295349,\n 466: 0.9841822981834412,\n 467: 0.9772180914878845,\n 468: 0.9664918184280396,\n 469: 0.9819689989089966,\n 470: 0.942360520362854,\n 471: 0.9787534475326538,\n 472: 0.9836812019348145,\n 473: 0.9668015241622925,\n 474: 0.9076484441757202,\n 475: 0.9338451623916626,\n 476: 0.9855393171310425,\n 477: 0.950903058052063,\n 478: 0.9738163352012634,\n 479: 0.9607383608818054,\n 480: 0.976142406463623,\n 481: 0.990217924118042,\n 482: 0.955031156539917,\n 483: 0.9813019633293152,\n 484: 0.8043007254600525,\n 485: 0.9572679996490479,\n 486: 0.9884282946586609,\n 487: 0.8178683519363403,\n 488: 0.9618024826049805,\n 489: 0.9808546900749207,\n 490: 0.9589269757270813,\n 491: 0.8979555368423462,\n 492: 0.9757923483848572,\n 493: 0.7426338791847229,\n 494: 0.9776803851127625,\n 495: 0.7013083100318909,\n 496: 0.9669833779335022,\n 497: 0.9787502884864807,\n 498: 0.9727296829223633,\n 499: 0.9794173836708069,\n 500: 0.9841898679733276,\n 501: 0.9531325101852417,\n 502: 0.8642594814300537,\n 503: 0.9804423451423645,\n 504: 0.8850480318069458,\n 505: 0.9113192558288574,\n 506: 0.98587965965271,\n 507: 0.9756577014923096,\n 508: 0.9805939793586731,\n 509: 0.9883362650871277,\n 510: 0.9478389024734497,\n 511: 0.9572884440422058,\n 512: 0.9043444395065308,\n 513: 0.9793924689292908,\n 514: 0.972728431224823,\n 515: 0.9408850073814392,\n 516: 0.9686917662620544,\n 517: 0.9821013808250427,\n 518: 0.876205563545227,\n 519: 0.9838178753852844,\n 520: 0.9320328831672668,\n 521: 0.9714930653572083,\n 522: 0.9325941801071167,\n 523: 0.9431009292602539,\n 524: 0.9788169860839844,\n 525: 0.9339354038238525,\n 526: 0.9545226693153381,\n 527: 0.9514983296394348,\n 528: 0.9688596129417419,\n 529: 0.9044797420501709,\n 530: 0.9896553754806519,\n 531: 0.6174934506416321,\n 532: 0.9497969150543213,\n 533: 0.8079925179481506,\n 534: 0.8278239965438843,\n 535: 0.9651563763618469,\n 536: 0.9677323698997498,\n 537: 0.9764673113822937,\n 538: 0.9800715446472168,\n 539: 0.9717172384262085,\n 540: 0.9153315424919128,\n 541: 0.9486995935440063,\n 542: 0.9642525911331177,\n 543: 0.9589018225669861,\n 544: 0.8863475918769836,\n 545: 0.986228346824646,\n 546: 0.6648433804512024,\n 547: 0.960349440574646,\n 548: 0.976801872253418,\n 549: 0.964759349822998,\n 550: 0.8080167770385742,\n 551: 0.9713101983070374,\n 552: 0.7879507541656494,\n 553: 0.9799226522445679,\n 554: 0.9812759160995483,\n 555: 0.9793683886528015,\n 556: 0.955719530582428,\n 557: 0.9548429846763611,\n 558: 0.9818823337554932,\n 559: 0.9683688879013062,\n 560: 0.9067444205284119,\n 561: 0.9696038961410522,\n 562: 0.9850658774375916,\n 563: 0.96711266040802,\n 564: 0.9317297339439392,\n 565: 0.9299464225769043,\n 566: 0.9772488474845886,\n 567: 0.8134519457817078,\n 568: 0.9576430916786194,\n 569: 0.9312630295753479,\n 570: 0.979904055595398,\n 571: 0.9761494994163513,\n 572: 0.9821748733520508,\n 573: 0.8280863761901855,\n 574: 0.9532474279403687,\n 575: 0.9710667133331299,\n 576: 0.9703910946846008,\n 577: 0.9824972152709961,\n 578: 0.9411492347717285,\n 579: 0.9760452508926392,\n 580: 0.9778764843940735,\n 581: 0.975303053855896,\n 582: 0.9680600762367249,\n 583: 0.8323625922203064,\n 584: 0.87496018409729,\n 585: 0.9764459729194641,\n 586: 0.9714115858078003,\n 587: 0.963590681552887,\n 588: 0.7340245246887207,\n 589: 0.5454406142234802,\n 590: 0.9940788745880127,\n 591: 0.9306651949882507,\n 592: 0.7315698266029358,\n 593: 0.8138101696968079,\n 594: 0.9349521398544312,\n 595: 0.9414137005805969,\n 596: 0.9788758158683777,\n 597: 0.9859182834625244,\n 598: 0.9901651740074158,\n 599: 0.9917386770248413,\n 600: 0.8972375392913818,\n 601: 0.9376447796821594,\n 602: 0.9488399624824524,\n 603: 0.9662412405014038,\n 604: 0.9439564943313599,\n 605: 0.9264540672302246,\n 606: 0.9628114700317383,\n 607: 0.8823651075363159,\n 608: 0.8325321674346924,\n 609: 0.960045337677002,\n 610: 0.9483160972595215,\n 611: 0.9647673964500427,\n 612: 0.971828043460846,\n 613: 0.9629889130592346,\n 614: 0.8596228361129761,\n 615: 0.9590863585472107,\n 616: 0.9641846418380737,\n 617: 0.9445406198501587,\n 618: 0.5670842528343201,\n 619: 0.9618600010871887,\n 620: 0.9571523666381836,\n 621: 0.9583023190498352,\n 622: 0.9867407083511353,\n 623: 0.9421828985214233,\n 624: 0.9663459658622742,\n 625: 0.9905473589897156,\n 626: 0.8880974054336548,\n 627: 0.9371121525764465,\n 628: 0.9811182022094727,\n 629: 0.8701352477073669,\n 630: 0.9675477147102356,\n 631: 0.9752503037452698,\n 632: 0.8727726340293884,\n 633: 0.955487072467804,\n 634: 0.9238969087600708,\n 635: 0.9590007662773132,\n 636: 0.9793252348899841,\n 637: 0.9143034219741821,\n 638: 0.9671820998191833,\n 639: 0.9622579216957092,\n 640: 0.9060360193252563,\n 641: 0.9117695689201355,\n 642: 0.9418218731880188,\n 643: 0.9652259349822998,\n 644: 0.9439740777015686,\n 645: 0.8459973931312561,\n 646: 0.49767956137657166,\n 647: 0.8821952939033508,\n 648: 0.9830997586250305,\n 649: 0.7864872813224792,\n 650: 0.9678624272346497,\n 651: 0.9751918315887451,\n 652: 0.856935977935791,\n 653: 0.913671612739563,\n 654: 0.9845868945121765,\n 655: 0.9656429290771484,\n 656: 0.9543745517730713,\n 657: 0.9915188550949097,\n 658: 0.8341167569160461,\n 659: 0.985628068447113,\n 660: 0.9769131541252136,\n 661: 0.9567064642906189,\n 662: 0.9835370779037476,\n 663: 0.9375268220901489,\n 664: 0.7052218914031982,\n 665: 0.9348044991493225,\n 666: 0.9709560871124268,\n 667: 0.9473708271980286,\n 668: 0.9170472621917725,\n 669: 0.9224703907966614,\n 670: 0.0,\n 671: 0.8191309571266174,\n 672: 0.7259159088134766,\n 673: 0.9093270301818848,\n 674: 0.7656627893447876,\n 675: 0.9600309133529663,\n 676: 0.9550755023956299,\n 677: 0.9603414535522461,\n 678: 0.9603574275970459,\n 679: 0.9829747080802917,\n 680: 0.9637786746025085,\n 681: 0.9600345492362976,\n 682: 0.9475946426391602,\n 683: 0.9352527260780334,\n 684: 0.6195930242538452,\n 685: 0.9520635604858398,\n 686: 0.985630989074707,\n 687: 0.9894328713417053,\n 688: 0.969103991985321,\n 689: 0.8987019658088684,\n 690: 0.8708658814430237,\n 691: 0.931976854801178,\n 692: 0.9746461510658264,\n 693: 0.9832398891448975,\n 694: 0.976747989654541,\n 695: 0.977318286895752,\n 696: 0.9591882228851318,\n 697: 0.9617177248001099,\n 698: 0.9683890342712402,\n 699: 0.837427020072937,\n 700: 0.9822536110877991,\n 701: 0.9393854141235352,\n 702: 0.5025849938392639,\n 703: 0.9361854195594788,\n 704: 0.8909975290298462,\n 705: 0.6207167506217957,\n 706: 0.643233597278595,\n 707: 0.974128246307373,\n 708: 0.9951276779174805,\n 709: 0.9539771676063538,\n 710: 0.9847787618637085,\n 711: 0.9696609377861023,\n 712: 0.6969848275184631,\n 713: 0.9578796029090881,\n 714: 0.8690572381019592,\n 715: 0.9673349261283875,\n 716: 0.9719606041908264,\n 717: 0.3753848075866699,\n 718: 0.9689618945121765,\n 719: 0.9794662594795227,\n 720: 0.9844663739204407,\n 721: 0.9757238030433655,\n 722: 0.9768787026405334,\n 723: 0.8054322004318237,\n 724: 0.9510694146156311,\n 725: 0.9614598155021667,\n 726: 0.34756335616111755,\n 727: 0.9886291027069092,\n 728: 0.929509162902832,\n 729: 0.07303043454885483,\n 730: 0.9878821969032288,\n 731: 0.9626831412315369,\n 732: 0.9917773604393005,\n 733: 0.9448347687721252,\n 734: 0.8531405925750732,\n 735: 0.9825764894485474,\n 736: 0.8995898962020874,\n 737: 0.839556097984314,\n 738: 0.9118114113807678,\n 739: 0.9832847714424133,\n 740: 0.9823911786079407,\n 741: 0.7943153381347656,\n 742: 0.9559070467948914,\n 743: 0.9822001457214355,\n 744: 0.9818475246429443,\n 745: 0.9890488386154175,\n 746: 0.9363946914672852,\n 747: 0.9876354932785034,\n 748: 0.9414514899253845,\n 749: 0.8666086196899414,\n 750: 0.963458776473999,\n 751: 0.9349241852760315,\n 752: 0.9749897122383118,\n 753: 0.9842656254768372,\n 754: 0.9730871319770813,\n 755: 0.9737464785575867,\n 756: 0.9700739979743958,\n 757: 0.8197387456893921,\n 758: 0.9504062533378601,\n 759: 0.9316624402999878,\n 760: 0.994740903377533,\n 761: 0.9552252888679504,\n 762: 0.9797690510749817,\n 763: 0.8800022602081299,\n 764: 0.7326365113258362,\n 765: 0.9794596433639526,\n 766: 0.6766173839569092,\n 767: 0.9098877310752869,\n 768: 0.9843876957893372,\n 769: 0.9666213989257812,\n 770: 0.9758154153823853,\n 771: 0.8666334748268127,\n 772: 0.979895830154419,\n 773: 0.9923909902572632,\n 774: 0.9745761752128601,\n 775: 0.9731230139732361,\n 776: 0.8534285426139832,\n 777: 0.9541682600975037,\n 778: 0.9228121042251587,\n 779: 0.9330828189849854,\n 780: 0.5585611462593079,\n 781: 0.16422078013420105,\n 782: 0.9231162667274475,\n 783: 0.905412495136261,\n 784: 0.9806150197982788,\n 785: 0.9671375751495361,\n 786: 0.8128346800804138,\n 787: 0.9725084900856018,\n 788: 0.9706940054893494,\n 789: 0.851849377155304,\n 790: 0.9726768732070923,\n 791: 0.9677377343177795,\n 792: 0.9441356062889099,\n 793: 0.8982692360877991,\n 794: 0.9811762571334839,\n 795: 0.9291938543319702,\n 796: 0.8398200273513794,\n 797: 0.5699446797370911,\n 798: 0.9739140868186951,\n 799: 0.8874607086181641,\n 800: 0.7940557599067688,\n 801: 0.9675920605659485,\n 802: 0.9894493222236633,\n 803: 0.9284630417823792,\n 804: 0.9023643732070923,\n 805: 0.4034344255924225,\n 806: 0.9852538704872131,\n 807: 0.9754031896591187,\n 808: 0.9675127863883972,\n 809: 0.985190212726593,\n 810: 0.9316839575767517,\n 811: 0.9793243408203125,\n 812: 0.9870834350585938,\n 813: 0.9874556660652161,\n 814: 0.7800421118736267,\n 815: 0.9875778555870056,\n 816: 0.948844850063324,\n 817: 0.9835399389266968,\n 818: 0.9920709729194641,\n 819: 0.9824529886245728,\n 820: 0.9774388074874878,\n 821: 0.9008162617683411,\n 822: 0.9795277714729309,\n 823: 0.9905263185501099,\n 824: 0.9745346903800964,\n 825: 0.948423445224762,\n 826: 0.5121508836746216,\n 827: 0.949485182762146,\n 828: 0.9079653024673462,\n 829: 0.9752927422523499,\n 830: 0.9636041522026062,\n 831: 0.913542628288269,\n 832: 0.9526004195213318,\n 833: 0.9281832575798035,\n 834: 0.7997230887413025,\n 835: 0.9536321759223938,\n 836: 0.8977873921394348,\n 837: 0.9511774778366089,\n 838: 0.9757606983184814,\n 839: 0.9821304678916931,\n 840: 0.9323086738586426,\n 841: 0.9239779114723206,\n 842: 0.8565122485160828,\n 843: 0.9605279564857483,\n 844: 0.9807376861572266,\n 845: 0.9481545686721802,\n 846: 0.964773952960968,\n 847: 0.9290347695350647,\n 848: 0.9646585583686829,\n 849: 0.9926333427429199,\n 850: 0.9109171628952026,\n 851: 0.9659536480903625,\n 852: 0.9538736939430237,\n 853: 0.9853432178497314,\n 854: 0.9681307077407837,\n 855: 0.9623451232910156,\n 856: 0.8489876985549927,\n 857: 0.9823982119560242,\n 858: 0.8324739336967468,\n 859: 0.9729630351066589,\n 860: 0.9771721363067627,\n 861: 0.9747981429100037,\n 862: 0.9882473349571228,\n 863: 0.9452620148658752,\n 864: 0.9480838775634766,\n 865: 0.9113178849220276,\n 866: 0.9901906847953796,\n 867: 0.9679490923881531,\n 868: 0.9719610214233398,\n 869: 0.9764032959938049,\n 870: 0.9838297367095947,\n 871: 0.8704723119735718,\n 872: 0.9719229340553284,\n 873: 0.9572243690490723,\n 874: 0.9719176292419434,\n 875: 0.9621821641921997,\n 876: 0.5332584381103516,\n 877: 0.9828327298164368,\n 878: 0.7948142290115356,\n 879: 0.9840568900108337,\n 880: 0.9712513089179993,\n 881: 0.979132354259491,\n 882: 0.932884693145752,\n 883: 0.9668154120445251,\n 884: 0.9795801639556885,\n 885: 0.968812108039856,\n 886: 0.9731897115707397,\n 887: 0.9697858095169067,\n 888: 0.4439490735530853,\n 889: 0.9430056214332581,\n 890: 0.9787989258766174,\n 891: 0.9706928730010986,\n 892: 0.9090774059295654,\n 893: 0.9778947234153748,\n 894: 0.9709529280662537,\n 895: 0.8597821593284607,\n 896: 0.9445798993110657,\n 897: 0.9843318462371826,\n 898: 0.9796808362007141,\n 899: 0.9712640643119812,\n 900: 0.8751386404037476,\n 901: 0.9272429943084717,\n 902: 0.9918134808540344,\n 903: 0.9434065222740173,\n 904: 0.9609806537628174,\n 905: 0.9098509550094604,\n 906: 0.9925296902656555,\n 907: 0.9694991707801819,\n 908: 0.9843781590461731,\n 909: 0.9750800132751465,\n 910: 0.9774587750434875,\n 911: 0.9855125546455383,\n 912: 0.9793425798416138,\n 913: 0.9578679800033569,\n 914: 0.9497898817062378,\n 915: 0.972015380859375,\n 916: 0.979474663734436,\n 917: 0.9775787591934204,\n 918: 0.9618898034095764,\n 919: 0.9775464534759521,\n 920: 0.798686683177948,\n 921: 0.9900283813476562,\n 922: 0.987922191619873,\n 923: 0.6794803142547607,\n 924: 0.9794308543205261,\n 925: 0.8068081140518188,\n 926: 0.9698385000228882,\n 927: 0.9680496454238892,\n 928: 0.9188732504844666,\n 929: 0.9398722052574158,\n 930: 0.979750394821167,\n 931: 0.9442392587661743,\n 932: 0.9632238745689392,\n 933: 0.9734534621238708,\n 934: 0.9906880259513855,\n 935: 0.9345895051956177,\n 936: 0.9593810439109802,\n 937: 0.9814358353614807,\n 938: 0.957705557346344,\n 939: 0.9286407828330994,\n 940: 0.9547303318977356,\n 941: 0.9744088053703308,\n 942: 0.8587646484375,\n 943: 0.9747618436813354,\n 944: 0.976418673992157,\n 945: 0.9631822109222412,\n 946: 0.9796906113624573,\n 947: 0.985723078250885,\n 948: 0.9666719436645508,\n 949: 0.948310911655426,\n 950: 0.8433234095573425,\n 951: 0.9577934741973877,\n 952: 0.9833857417106628,\n 953: 0.9930558204650879,\n 954: 0.9756081104278564,\n 955: 0.7039140462875366,\n 956: 0.9770500659942627,\n 957: 0.9827554225921631,\n 958: 0.9852919578552246,\n 959: 0.9273251891136169,\n 960: 0.9699262976646423,\n 961: 0.9694273471832275,\n 962: 0.9904996752738953,\n 963: 0.9403250217437744,\n 964: 0.9647444486618042,\n 965: 0.9628440141677856,\n 966: 0.6673880219459534,\n 967: 0.6149845719337463,\n 968: 0.9481386542320251,\n 969: 0.976170003414154,\n 970: 0.6329789757728577,\n 971: 0.941699743270874,\n 972: 0.9696916341781616,\n 973: 0.844312310218811,\n 974: 0.9612413644790649,\n 975: 0.7233338952064514,\n 976: 0.9672739505767822,\n 977: 0.9817447662353516,\n 978: 0.9820191860198975,\n 979: 0.9700717329978943,\n 980: 0.9469554424285889,\n 981: 0.7779882550239563,\n 982: 0.9890167713165283,\n 983: 0.9913235306739807,\n 984: 0.9671342372894287,\n 985: 0.9630064368247986,\n 986: 0.9501527547836304,\n 987: 0.9709182977676392,\n 988: 0.9100164175033569,\n 989: 0.7102217674255371,\n 990: 0.9593023657798767,\n 991: 0.7945843935012817,\n 992: 0.8733530640602112,\n 993: 0.9214600324630737,\n 994: 0.7548255324363708,\n 995: 0.9076265096664429,\n 996: 0.9404439330101013,\n 997: 0.9777328372001648,\n 998: 0.15819258987903595,\n 999: 0.9989885091781616,\n ...}"
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = ProxyCalculator(\"proxies\", \"proxy_metric\")\n",
    "pc.load()\n",
    "\n",
    "pc.calculate_proxy_scores()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "class ProbeSuiteGenerator(Dataset):\n",
    "    dataset: Dataset\n",
    "    remaining_indices: list = []\n",
    "    used_indices: list = []\n",
    "    dataset_len: int\n",
    "    label_count: int\n",
    "    proxy_calculator: ProxyCalculator\n",
    "\n",
    "    suites: Dict[int, Tuple[Tuple[torch.Tensor, int], int]] = {}\n",
    "    index_to_suite: Dict[int, str] = {}\n",
    "\n",
    "    only_probes: bool = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        label_count: int,\n",
    "        proxy_calculator: ProxyCalculator,\n",
    "        num_probes: int = 500,\n",
    "        corruption_module: Optional[Union[torch.nn.Module, transforms.Compose]] = None,\n",
    "        only_probes: bool = False,\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.dataset_len = len(self.dataset)\n",
    "        self.used_indices = []\n",
    "        self.remaining_indices = list(range(self.dataset_len))\n",
    "        self.label_count = label_count\n",
    "        self.num_probes = num_probes\n",
    "\n",
    "        self.corruption_module = corruption_module\n",
    "        self.only_probes = only_probes\n",
    "\n",
    "        self.proxy_calculator = proxy_calculator\n",
    "        self.scores = proxy_calculator.calculate_proxy_scores()\n",
    "        self.sorted_indices = list(\n",
    "            dict(sorted(self.scores.items(), key=lambda x: x[1], reverse=True)).keys()\n",
    "        )\n",
    "\n",
    "        assert len(self.scores) == self.dataset_len\n",
    "\n",
    "        self.suites = {}\n",
    "        self.index_to_suite = {}\n",
    "\n",
    "    def generate(self):\n",
    "        self.generate_atypical()\n",
    "        self.generate_typical()\n",
    "        self.generate_random_outputs()\n",
    "        self.generate_random_inputs_outputs()\n",
    "        if self.corruption_module is not None:\n",
    "            self.generate_corrupted()\n",
    "\n",
    "        assert len(np.intersect1d(self.remaining_indices, self.used_indices)) == 0\n",
    "        assert (\n",
    "            len(np.unique(self.remaining_indices + self.used_indices))\n",
    "            == self.dataset_len\n",
    "        )\n",
    "        assert (\n",
    "            len(np.unique(self.remaining_indices)) + len(np.unique(self.used_indices))\n",
    "            == self.dataset_len\n",
    "        )\n",
    "\n",
    "    def add_suite(\n",
    "        self, name: str, suite: List[Tuple[torch.Tensor, int, int]]\n",
    "    ) -> \"ProbeSuiteGenerator\":\n",
    "        for (sample, target), idx in suite:\n",
    "            self.index_to_suite[idx] = name\n",
    "            self.suites[idx] = ((sample, target), idx)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def generate_typical(self):\n",
    "        subset = self.get_subset(indices=self.sorted_indices[: self.num_probes])\n",
    "        suite = [((x, y), idx) for (x, y), idx in subset]\n",
    "\n",
    "        self.add_suite(\"typical\", suite)\n",
    "\n",
    "    def generate_atypical(self):\n",
    "        subset = self.get_subset(\n",
    "            indices=self.sorted_indices[-self.num_probes :]  # noqa: E203\n",
    "        )  # noqa: E203\n",
    "        atypical = [((x, y), idx) for (x, y), idx in subset]\n",
    "\n",
    "        self.add_suite(\"atypical\", atypical)\n",
    "\n",
    "    def generate_random_outputs(self):\n",
    "        subset = self.get_subset()\n",
    "        suite = [\n",
    "            (\n",
    "                (x, random.choice([i for i in range(self.label_count) if i != y])),\n",
    "                idx,\n",
    "            )\n",
    "            for (x, y), idx in subset\n",
    "        ]\n",
    "\n",
    "        self.add_suite(\"random_outputs\", suite)\n",
    "\n",
    "    def generate_random_inputs_outputs(self):\n",
    "        subset = self.get_subset()\n",
    "\n",
    "        suite = [\n",
    "            ((torch.rand_like(x), torch.randint(0, self.label_count, (1,)).item()), idx)\n",
    "            for (x, y), idx in subset\n",
    "        ]\n",
    "\n",
    "        self.add_suite(\"random_inputs_outputs\", suite)\n",
    "\n",
    "    def generate_corrupted(self):\n",
    "        subset = self.get_subset()\n",
    "\n",
    "        suite = [\n",
    "            ((self.corruption_module(x), y), idx)\n",
    "            for (x, y), idx in subset\n",
    "        ]\n",
    "\n",
    "        self.add_suite(\"corrupted\", suite)\n",
    "\n",
    "    def get_subset(\n",
    "        self,\n",
    "        indices: Optional[list[int]] = None,\n",
    "    ) -> Subset:\n",
    "        if indices is None:\n",
    "            subset_indices = np.random.choice(\n",
    "                self.remaining_indices, self.num_probes, replace=False\n",
    "            ).tolist()\n",
    "        else:\n",
    "            subset_indices = indices\n",
    "\n",
    "        self.used_indices.extend(subset_indices)\n",
    "        self.remaining_indices = [\n",
    "            idx for idx in self.remaining_indices if idx not in subset_indices\n",
    "        ]\n",
    "\n",
    "        return Subset(self.dataset, subset_indices)\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[Tuple[torch.Tensor, int], int]:\n",
    "        if self.only_probes:\n",
    "            keys = list(self.suites.keys())\n",
    "\n",
    "            return self.suites[keys[index]]\n",
    "\n",
    "        if index in self.used_indices:\n",
    "            return self.suites[index]\n",
    "\n",
    "        sample, target = self.dataset[index]\n",
    "\n",
    "        return (sample, target), index\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.only_probes:\n",
    "            return len(self.index_to_suite)\n",
    "\n",
    "        return self.dataset_len\n",
    "\n",
    "\n",
    "def make_probe_suites(\n",
    "    dataset: Dataset,\n",
    "    label_count: int,\n",
    "    proxy_calculator: ProxyCalculator,\n",
    "    num_probes: int = 500\n",
    "):\n",
    "    probe_suite = ProbeSuiteGenerator(\n",
    "        dataset,\n",
    "        label_count,\n",
    "        num_probes=num_probes,\n",
    "        proxy_calculator=proxy_calculator,\n",
    "    )\n",
    "    probe_suite.generate()\n",
    "\n",
    "    return probe_suite"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "dm.setup(\"train\")\n",
    "probe_suite_ds = make_probe_suites(dm.mnist_train, 10, pc, num_probes=500)\n",
    "\n",
    "def make_dataloaders(validation_dataloaders: List[DataLoader], probe_suite_dataset: ProbeSuiteGenerator, dataloader_kwargs: Optional[dict] = None):\n",
    "    default_dataloader_options = {\n",
    "        \"batch_size\": 512,\n",
    "        \"num_workers\": 1,\n",
    "        \"prefetch_factor\": 1\n",
    "    }\n",
    "\n",
    "    if dataloader_kwargs is not None:\n",
    "        default_dataloader_options.update(dataloader_kwargs)\n",
    "\n",
    "    probe_suite_dataset = deepcopy(probe_suite_dataset)\n",
    "    probe_suite_dataset.only_probes = True\n",
    "    probe_suite_dataset.dataset = None\n",
    "\n",
    "    return [DataLoader(probe_suite_dataset, **default_dataloader_options)] + validation_dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | Net  | 21.8 K\n",
      "-------------------------------\n",
      "21.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.8 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74586231ad074a319f6f15ce918faf80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonashoffmann/.applications/miniconda3/envs/mapd-pkg/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jonashoffmann/.applications/miniconda3/envs/mapd-pkg/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4507c771d583439dac39248d3aceadaf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c80e461ec5c47d68419ac5e9889cada"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61ab1e7d016a4fec8b344ac5059178c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c25bf86a7d94bc3833e9ca73724fd5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ee8d5c19763448995feb301e98b8a73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3cda73c4ef74c7d9bc9ad7cc1b0996e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "568285c375e64fba84a0661c301d62e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d485a4f1ba5f4480a59591e0aa42ccc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7df38ea346dc4479811d12a0ca3547ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc1838765125475cadf017a4ecba64cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29eaf5903b464b8fb9aa0e4d90c5a39c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02bed529a5e74596b2fddc956f2eed57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f93da4d83fb48139649e143cff96b08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b6691e77dc744ffbc81af5148cfa3b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fba10c9adb2d4d8280458953675fd173"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33d0df0c9cb84d7fa03bbdff1522e928"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3661ac9eb99b44918324029591647b4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5dd653fb6a54a63887d3d6692202f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ad21a1762504114bf70a4353d6b0f52"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a095d85875dd407a9eb3290a8484fd2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7c69b5058964e8089f87f4f77141431"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef20d13895804b148014f9e48748c07a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bba83ad2ab94f1f926d94aa010ae9d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f5fde37cfa6490f9833a09bb74ed9ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86af54d516064dc1a46ae70068ade556"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ee7c6c17b444b90a1bd2671841edd26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9bcffeb39ad47559161e91de4aa9947"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "795c9cb8008e48d19a5bde804ba579a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a5f71cc8ee24aed96c5fa1f59dd2f80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50db99d4a5a940478a4c6c2765463175"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "544a53fb828c44aea62df4dde7edbde7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c346221c94de459780b650293c26de97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "195235672dc44efabed8fef7feb8f2ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e473f8200af4066833d6d57d86ecfc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4961d0b77dda4179a5b712e6a8af67f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "415b3b58cc6e4c6786d6375f9b383ed9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f765c78d35014013a7a149ab1fef1325"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90bdb45f77924c8e828be6bb7114708c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c5dad31b3094deeb708b4671d75d768"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30dbeca7b7974e8d9e71f1f40aa719df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e6ae6f8132c45a18ee4c5148a7c6c96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a687ef276eff47fda27388b6c27cdcc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26406be8ce414cf69b59427a7d212fac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e1a45f84d1d45dea0027f887f35ee1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6e10e2d7d11456c872389c265757ee6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f1f1442b08b44f8aab4cf158cc92570"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c84c91883c34e06a0abf4ae6e16f88c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03b7b5087e984919a32d8e15ac0b573e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdf78e85a8a842268dc9dfb11f8c5de8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7f6117bd2ec49878e954a201652d026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99a2620876a244f6b326f56fc1929bc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4da928ea071e42829a7aded3dc80e922"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6839513ce494fa48d000268ca48fcce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "265b7b5e54914c02b2d6e5bde6473e4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b737725152334812aa72764829ad5d41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df1fa3d8829d42a1b175ef1533657fbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e8a5ff951ca49bc8474a46a6df0b7e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5f29aa00a014f98b0ee3d185729d1e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9545c5deeb67403bbfa79378e60dd997"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ab81c265cab4af7acb4a0fd74856f4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a21aa04cd7aa468e96c562d6f2d08a08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5fde38caa074f1883f213d8ca4da6dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8931c2860c844d0bd043c4a2e473ec8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64b49f4eceff4bf98e2a76cd2afd2cdc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09c0594c273042499404db191ee86445"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2a50202ba064bda8d402d0fe0f88728"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b057f8196ebf496485403245588e98da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3306304c3094c2e80c792ad7f0f1026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d27bc63480fc4af59e69a469bd4bafab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d7bab33ab1242cba76bd748c5add67d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bedcaa126244a74afa6f261152adec0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27cb3bdc41464bcd930316487adccc74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4103c243964645a58756e123b868e1b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fba27820dbaa47f498e49db30cdc8bfc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa709fcf79a64e29996e2e1ab49cb8e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13d54557d50a49898c648f2802872fbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48aeeb472ff6427c8c833461fe4eb51f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92c39bb7c6dc483ba081b4f38a4ca2e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a929a69ee43d45cfa8c0f2d86f7ad6ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b32870e746142909f3ad707fbb81816"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "212fb32579e8495eafc52e1c1fe39001"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b9f555bc7e64029850d91c49a6156af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "259f565923004eadb6d0c0e539ac0c03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82c0fe7c66cb4b6e9205acdbe0eacc12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0bb633f47694da0b9ad2ea4188423ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6602609052bc4430b9a4763c324afe6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e392e897378e47f1b0c35bf93b110cb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d811839eafe34323ad588f5e9b316071"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06aec73c849e4e4da6d2357f1e0f94a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "924ae84d89834cb1bd7714c72ea13794"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b2499b8464f4adf90f5c4f71fb65541"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13bf4cc9a1084ed9badef09b6d7a1602"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81dc8f9ddfea43ab93aed30fdb68effc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9707a9e961d4d7a855d54d90294e6fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a77fe1a32634f68950c787fdbace87a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4eb3c887b26845f3a58bb75a937b3919"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e8a93bf53234df9bf484b6326dd4fbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f05a12ccc2d4c15a2016ddc8e961aca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69e60aa04cc947359697bc9be43ab653"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d024e558d2014a4380cdeab1d504c38e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca25d6ea9cd343378a8f323013ea02d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "dl_probes = DataLoader(mnist_train, batch_size=512, shuffle=True, num_workers=16, prefetch_factor=8)\n",
    "\n",
    "val_dataloader = DataLoader(IDXDataset(mnist_val), batch_size=512, shuffle=True, num_workers=16, prefetch_factor=8)\n",
    "val_dataloaders = make_dataloaders([val_dataloader], probe_suite_ds)\n",
    "\n",
    "trainer_probes.fit(module.as_probes(probe_suite_ds), train_dataloaders=dl_probes, val_dataloaders=val_dataloaders)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(l) for l in module.mapd_losses_])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [],
   "source": [
    "probes = ds.dataset(\"probes\", partitioning=ds.partitioning(pa.schema([(\"epoch\", pa.int64()), (\"stage\", pa.string())]), flavor=\"filename\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "data": {
      "text/plain": "5700000"
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probes.to_table())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
